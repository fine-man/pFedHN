{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# some magic so that the notebook will reload external python modules;\n",
    "# see https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from tqdm import trange\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.pfedhn.models import CNNHyper, CNNTarget\n",
    "from experiments.pfedhn.node import BaseNodes\n",
    "from experiments.utils import get_device, set_logger, set_seed, str2bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(nodes, num_nodes, hnet, net, criteria, device, split):\n",
    "    curr_results = evaluate(nodes, num_nodes, hnet, net, criteria, device, split=split)\n",
    "    total_correct = sum([val['correct'] for val in curr_results.values()])\n",
    "    total_samples = sum([val['total'] for val in curr_results.values()])\n",
    "    avg_loss = np.mean([val['loss'] for val in curr_results.values()])\n",
    "    avg_acc = total_correct / total_samples\n",
    "\n",
    "    all_acc = [val['correct'] / val['total'] for val in curr_results.values()]\n",
    "\n",
    "    return curr_results, avg_loss, avg_acc, all_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(nodes: BaseNodes, num_nodes, hnet, net, criteria, device, split='test'):\n",
    "    hnet.eval()\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for node_id in range(num_nodes):  # iterating over nodes\n",
    "\n",
    "        running_loss, running_correct, running_samples = 0., 0., 0.\n",
    "        if split == 'test':\n",
    "            curr_data = nodes.test_loaders[node_id]\n",
    "        elif split == 'val':\n",
    "            curr_data = nodes.val_loaders[node_id]\n",
    "        else:\n",
    "            curr_data = nodes.train_loaders[node_id]\n",
    "\n",
    "        for batch_count, batch in enumerate(curr_data):\n",
    "            img, label = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            weights = hnet(torch.tensor([node_id], dtype=torch.long).to(device))\n",
    "            net.load_state_dict(weights)\n",
    "            pred = net(img)\n",
    "            running_loss += criteria(pred, label).item()\n",
    "            running_correct += pred.argmax(1).eq(label).sum().item()\n",
    "            running_samples += len(label)\n",
    "\n",
    "        results[node_id]['loss'] = running_loss / (batch_count + 1)\n",
    "        results[node_id]['correct'] = running_correct\n",
    "        results[node_id]['total'] = running_samples\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mse(data_name: str, data_path: str, classes_per_node: int, num_nodes: int,\n",
    "          steps: int, inner_steps: int, optim: str, lr: float, inner_lr: float,\n",
    "          embed_lr: float, wd: float, inner_wd: float, embed_dim: int, hyper_hid: int,\n",
    "          n_hidden: int, n_kernels: int, bs: int, device, eval_every: int, save_path: Path,\n",
    "          seed: int) -> None:\n",
    "\n",
    "    ###############################\n",
    "    # init nodes, hnet, local net #\n",
    "    ###############################\n",
    "    nodes = BaseNodes(data_name, data_path, num_nodes, classes_per_node=classes_per_node,\n",
    "                      batch_size=bs)\n",
    "\n",
    "    embed_dim = embed_dim\n",
    "    if embed_dim == -1:\n",
    "        logging.info(\"auto embedding size\")\n",
    "        embed_dim = int(1 + num_nodes / 4)\n",
    "\n",
    "    if data_name == \"cifar10\":\n",
    "        hnet = CNNHyper(num_nodes, embed_dim, hidden_dim=hyper_hid, n_hidden=n_hidden, n_kernels=n_kernels)\n",
    "        net = CNNTarget(n_kernels=n_kernels)\n",
    "    elif data_name == \"cifar100\":\n",
    "        hnet = CNNHyper(num_nodes, embed_dim, hidden_dim=hyper_hid,\n",
    "                        n_hidden=n_hidden, n_kernels=n_kernels, out_dim=100)\n",
    "        net = CNNTarget(n_kernels=n_kernels, out_dim=100)\n",
    "    else:\n",
    "        raise ValueError(\"choose data_name from ['cifar10', 'cifar100']\")\n",
    "\n",
    "    hnet = hnet.to(device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    ##################\n",
    "    # init optimizer #\n",
    "    ##################\n",
    "    embed_lr = embed_lr if embed_lr is not None else lr\n",
    "    optimizers = {\n",
    "        'sgd': torch.optim.SGD(\n",
    "            [\n",
    "                {'params': [p for n, p in hnet.named_parameters() if 'embed' not in n]},\n",
    "                {'params': [p for n, p in hnet.named_parameters() if 'embed' in n], 'lr': embed_lr}\n",
    "            ], lr=lr, momentum=0.9, weight_decay=wd\n",
    "        ),\n",
    "        'adam': torch.optim.Adam(params=hnet.parameters(), lr=lr)\n",
    "    }\n",
    "    optimizer = optimizers[optim]\n",
    "    criteria = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ################\n",
    "    # init metrics #\n",
    "    ################\n",
    "    last_eval = -1\n",
    "    best_step = -1\n",
    "    best_acc = -1\n",
    "    test_best_based_on_step, test_best_min_based_on_step = -1, -1\n",
    "    test_best_max_based_on_step, test_best_std_based_on_step = -1, -1\n",
    "    step_iter = trange(steps)\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    for step in step_iter:\n",
    "        hnet.train()\n",
    "\n",
    "        # select client at random\n",
    "        node_id = random.choice(range(num_nodes))\n",
    "\n",
    "        # produce & load local network weights\n",
    "        weights = hnet(torch.tensor([node_id], dtype=torch.long).to(device))\n",
    "        net.load_state_dict(weights)\n",
    "\n",
    "        # init inner optimizer\n",
    "        inner_optim = torch.optim.SGD(\n",
    "            net.parameters(), lr=inner_lr, momentum=.9, weight_decay=inner_wd\n",
    "        )\n",
    "\n",
    "        # storing theta_i for later calculating delta theta\n",
    "        inner_state = OrderedDict({k: tensor for k, tensor in weights.items()})\n",
    "\n",
    "        # NOTE: evaluation on sent model\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            batch = next(iter(nodes.test_loaders[node_id]))\n",
    "            img, label = tuple(t.to(device) for t in batch)\n",
    "            pred = net(img)\n",
    "            prvs_loss = criteria(pred, label)\n",
    "            prvs_acc = pred.argmax(1).eq(label).sum().item() / len(label)\n",
    "            net.train()\n",
    "\n",
    "        # inner updates -> obtaining theta_tilda\n",
    "        for i in range(inner_steps):\n",
    "            net.train()\n",
    "            inner_optim.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch = next(iter(nodes.train_loaders[node_id]))\n",
    "            img, label = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            pred = net(img)\n",
    "\n",
    "            loss = criteria(pred, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 50)\n",
    "\n",
    "            inner_optim.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        final_state = net.state_dict()\n",
    "\n",
    "        # Calculating MSE Loss for the predicted HyperNetwork weights\n",
    "        hn_loss = 0.0\n",
    "        for key in weights.keys():\n",
    "            weight_loss = nn.MSELoss()(inner_state[key], final_state[key])\n",
    "            hn_loss += weight_loss\n",
    "        \n",
    "        hn_loss.backward()\n",
    "\n",
    "        # # calculating delta theta\n",
    "        # delta_theta = OrderedDict({k: inner_state[k] - final_state[k] for k in weights.keys()})\n",
    "\n",
    "        # # calculating phi gradient\n",
    "        # hnet_grads = torch.autograd.grad(\n",
    "        #     list(weights.values()), hnet.parameters(), grad_outputs=list(delta_theta.values())\n",
    "        # )\n",
    "\n",
    "        # # update hnet weights\n",
    "        # for p, g in zip(hnet.parameters(), hnet_grads):\n",
    "        #     p.grad = g\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(hnet.parameters(), 50)\n",
    "        optimizer.step()\n",
    "\n",
    "        step_iter.set_description(\n",
    "            f\"Step: {step+1}, Node ID: {node_id}, Loss: {prvs_loss:.4f},  Acc: {prvs_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        if step % eval_every == 0:\n",
    "            last_eval = step\n",
    "            step_results, avg_loss, avg_acc, all_acc = eval_model(nodes, num_nodes, hnet, net, criteria, device, split=\"test\")\n",
    "            logging.info(f\"\\n\\nStep: {step+1}, AVG Loss: {avg_loss:.4f},  AVG Acc: {avg_acc:.4f}, HN Loss: {hn_loss}\")\n",
    "\n",
    "            results['test_avg_loss'].append(avg_loss)\n",
    "            results['test_avg_acc'].append(avg_acc)\n",
    "\n",
    "            _, val_avg_loss, val_avg_acc, _ = eval_model(nodes, num_nodes, hnet, net, criteria, device, split=\"val\")\n",
    "            if best_acc < val_avg_acc:\n",
    "                best_acc = val_avg_acc\n",
    "                best_step = step\n",
    "                test_best_based_on_step = avg_acc\n",
    "                test_best_min_based_on_step = np.min(all_acc)\n",
    "                test_best_max_based_on_step = np.max(all_acc)\n",
    "                test_best_std_based_on_step = np.std(all_acc)\n",
    "\n",
    "            results['val_avg_loss'].append(val_avg_loss)\n",
    "            results['val_avg_acc'].append(val_avg_acc)\n",
    "            results['best_step'].append(best_step)\n",
    "            results['best_val_acc'].append(best_acc)\n",
    "            results['best_test_acc_based_on_val_beststep'].append(test_best_based_on_step)\n",
    "            results['test_best_min_based_on_step'].append(test_best_min_based_on_step)\n",
    "            results['test_best_max_based_on_step'].append(test_best_max_based_on_step)\n",
    "            results['test_best_std_based_on_step'].append(test_best_std_based_on_step)\n",
    "\n",
    "            # Wandb logging\n",
    "            wandb_dict = defaultdict(int)\n",
    "            wandb_dict[\"step\"] = step\n",
    "            wandb_dict[\"hn_loss\"] = hn_loss.detach().item()\n",
    "            for key, value_list in results.items():\n",
    "                wandb_dict[key] = value_list[-1]\n",
    "            # wandb.log(wandb_dict)\n",
    "\n",
    "            # Weights logging\n",
    "            weights_dict = defaultdict(int)\n",
    "            for name, param in hnet.named_parameters():\n",
    "                weights_dict[name] = param.detach().norm().item()\n",
    "            # wandb.log(weights_dict)\n",
    "\n",
    "    if step != last_eval:\n",
    "        _, val_avg_loss, val_avg_acc, _ = eval_model(nodes, num_nodes, hnet, net, criteria, device, split=\"val\")\n",
    "        step_results, avg_loss, avg_acc, all_acc = eval_model(nodes, num_nodes, hnet, net, criteria, device, split=\"test\")\n",
    "        logging.info(f\"\\nStep: {step + 1}, AVG Loss: {avg_loss:.4f},  AVG Acc: {avg_acc:.4f}\")\n",
    "\n",
    "        results['test_avg_loss'].append(avg_loss)\n",
    "        results['test_avg_acc'].append(avg_acc)\n",
    "\n",
    "        if best_acc < val_avg_acc:\n",
    "            best_acc = val_avg_acc\n",
    "            best_step = step\n",
    "            test_best_based_on_step = avg_acc\n",
    "            test_best_min_based_on_step = np.min(all_acc)\n",
    "            test_best_max_based_on_step = np.max(all_acc)\n",
    "            test_best_std_based_on_step = np.std(all_acc)\n",
    "\n",
    "        results['val_avg_loss'].append(val_avg_loss)\n",
    "        results['val_avg_acc'].append(val_avg_acc)\n",
    "        results['best_step'].append(best_step)\n",
    "        results['best_val_acc'].append(best_acc)\n",
    "        results['best_test_acc_based_on_val_beststep'].append(test_best_based_on_step)\n",
    "        results['test_best_min_based_on_step'].append(test_best_min_based_on_step)\n",
    "        results['test_best_max_based_on_step'].append(test_best_max_based_on_step)\n",
    "        results['test_best_std_based_on_step'].append(test_best_std_based_on_step)\n",
    "\n",
    "    save_path = Path(save_path)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    with open(str(save_path / f\"results_{inner_steps}_inner_steps_seed_{seed}.json\"), \"w\") as file:\n",
    "        json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(x, y):\n",
    "    diff = (x - y).flatten()\n",
    "    idx = torch.argmax(diff.abs())\n",
    "    sign = 1 if diff[idx] >= 0 else -1\n",
    "    return sign * torch.max(torch.abs(x - y)/(torch.maximum(torch.abs(x), torch.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Federated Hypernetwork with Lookahead experiment\"\n",
    ")\n",
    "\n",
    "#############################\n",
    "#       Dataset Args        #\n",
    "#############################\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--data-name\", type=str, default=\"cifar10\", choices=['cifar10', 'cifar100'], help=\"dir path for MNIST dataset\"\n",
    ")\n",
    "parser.add_argument(\"--data-path\", type=str, default=\"data\", help=\"dir path for MNIST dataset\")\n",
    "parser.add_argument(\"--num-nodes\", type=int, default=50, help=\"number of simulated nodes\")\n",
    "\n",
    "##################################\n",
    "#       Optimization args        #\n",
    "##################################\n",
    "\n",
    "parser.add_argument(\"--num-steps\", type=int, default=5000)\n",
    "parser.add_argument(\"--optim\", type=str, default='sgd', choices=['adam', 'sgd'], help=\"learning rate\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=64)\n",
    "parser.add_argument(\"--inner-steps\", type=int, default=50, help=\"number of inner steps\")\n",
    "\n",
    "################################\n",
    "#       Model Prop args        #\n",
    "################################\n",
    "parser.add_argument(\"--n-hidden\", type=int, default=3, help=\"num. hidden layers\")\n",
    "parser.add_argument(\"--inner-lr\", type=float, default=5e-3, help=\"learning rate for inner optimizer\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-2, help=\"learning rate\")\n",
    "parser.add_argument(\"--wd\", type=float, default=1e-3, help=\"weight decay\")\n",
    "parser.add_argument(\"--inner-wd\", type=float, default=5e-5, help=\"inner weight decay\")\n",
    "parser.add_argument(\"--embed-dim\", type=int, default=-1, help=\"embedding dim\")\n",
    "parser.add_argument(\"--embed-lr\", type=float, default=None, help=\"embedding learning rate\")\n",
    "parser.add_argument(\"--hyper-hid\", type=int, default=100, help=\"hypernet hidden dim\")\n",
    "parser.add_argument(\"--spec-norm\", type=str2bool, default=False, help=\"hypernet hidden dim\")\n",
    "parser.add_argument(\"--nkernels\", type=int, default=16, help=\"number of kernels for cnn model\")\n",
    "\n",
    "#############################\n",
    "#       General args        #\n",
    "#############################\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu device ID\")\n",
    "parser.add_argument(\"--eval-every\", type=int, default=5, help=\"eval every X selected epochs\")\n",
    "parser.add_argument(\"--save-path\", type=str, default=\"pfedhn_hetro_res\", help=\"dir path for output file\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"seed value\")\n",
    "\n",
    "args = parser.parse_args({})\n",
    "assert args.gpu <= torch.cuda.device_count(), f\"--gpu flag should be in range [0,{torch.cuda.device_count() - 1}]\"\n",
    "\n",
    "set_logger()\n",
    "set_seed(args.seed)\n",
    "\n",
    "device = get_device(gpus=args.gpu)\n",
    "\n",
    "if args.data_name == 'cifar10':\n",
    "    args.classes_per_node = 2\n",
    "else:\n",
    "    args.classes_per_node = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 18:32:04,424 - root - INFO - auto embedding size\n",
      "Step: 1, Node ID: 26, Loss: 2.1623,  Acc: 0.3438:   0%|          | 0/5000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\n\u001b[1;32m      2\u001b[0m     data_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_name,\n\u001b[1;32m      3\u001b[0m     data_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m      4\u001b[0m     classes_per_node\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mclasses_per_node,\n\u001b[1;32m      5\u001b[0m     num_nodes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_nodes,\n\u001b[1;32m      6\u001b[0m     steps\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_steps,\n\u001b[1;32m      7\u001b[0m     inner_steps\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_steps,\n\u001b[1;32m      8\u001b[0m     optim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39moptim,\n\u001b[1;32m      9\u001b[0m     lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlr,\n\u001b[1;32m     10\u001b[0m     inner_lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_lr,\n\u001b[1;32m     11\u001b[0m     embed_lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membed_lr,\n\u001b[1;32m     12\u001b[0m     wd\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwd,\n\u001b[1;32m     13\u001b[0m     inner_wd\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_wd,\n\u001b[1;32m     14\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[1;32m     15\u001b[0m     hyper_hid\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhyper_hid,\n\u001b[1;32m     16\u001b[0m     n_hidden\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mn_hidden,\n\u001b[1;32m     17\u001b[0m     n_kernels\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnkernels,\n\u001b[1;32m     18\u001b[0m     bs\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     19\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     20\u001b[0m     eval_every\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39meval_every,\n\u001b[1;32m     21\u001b[0m     save_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msave_path,\n\u001b[1;32m     22\u001b[0m )\n",
      "Cell \u001b[0;32mIn[106], line 143\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data_name, data_path, classes_per_node, num_nodes, steps, inner_steps, optim, lr, inner_lr, embed_lr, wd, inner_wd, embed_dim, hyper_hid, n_hidden, n_kernels, bs, device, eval_every, save_path)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m     last_eval \u001b[38;5;241m=\u001b[39m step\n\u001b[0;32m--> 143\u001b[0m     step_results, avg_loss, avg_acc, all_acc \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[1;32m    144\u001b[0m         nodes, num_nodes, hnet, net, criteria, device, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AVG Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  AVG Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, HN Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhn_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_avg_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(nodes, num_nodes, hnet, net, criteria, device, split)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_model\u001b[39m(nodes, num_nodes, hnet, net, criteria, device, split):\n\u001b[0;32m----> 2\u001b[0m     curr_results \u001b[38;5;241m=\u001b[39m evaluate(nodes, num_nodes, hnet, net, criteria, device, split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m      3\u001b[0m     total_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m curr_results\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[1;32m      4\u001b[0m     total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m curr_results\u001b[38;5;241m.\u001b[39mvalues()])\n",
      "File \u001b[0;32m~/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[105], line 32\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(nodes, num_nodes, hnet, net, criteria, device, split)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_count, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(curr_data):\n\u001b[1;32m     31\u001b[0m     img, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[0;32m---> 32\u001b[0m     net_out \u001b[38;5;241m=\u001b[39m net(img)\n\u001b[1;32m     33\u001b[0m     pred \u001b[38;5;241m=\u001b[39m nodes\u001b[38;5;241m.\u001b[39mlocal_layers[node_id](net_out)\n\u001b[1;32m     34\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criteria(pred, label)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pFedHN/experiments/pfedhn_pc/models.py:119\u001b[0m, in \u001b[0;36mCNNTargetPC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m--> 119\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    data_name=args.data_name,\n",
    "    data_path=args.data_path,\n",
    "    classes_per_node=args.classes_per_node,\n",
    "    num_nodes=args.num_nodes,\n",
    "    steps=args.num_steps,\n",
    "    inner_steps=args.inner_steps,\n",
    "    optim=args.optim,\n",
    "    lr=args.lr,\n",
    "    inner_lr=args.inner_lr,\n",
    "    embed_lr=args.embed_lr,\n",
    "    wd=args.wd,\n",
    "    inner_wd=args.inner_wd,\n",
    "    embed_dim=args.embed_dim,\n",
    "    hyper_hid=args.hyper_hid,\n",
    "    n_hidden=args.n_hidden,\n",
    "    n_kernels=args.nkernels,\n",
    "    bs=args.batch_size,\n",
    "    device=device,\n",
    "    eval_every=args.eval_every,\n",
    "    save_path=args.save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 02:27:33,194 - root - INFO - auto embedding size\n",
      "Step: 1, Node ID: 23, Loss: 2.3157,  Acc: 0.0781:   0%|          | 0/5000 [00:01<?, ?it/s]2024-01-27 02:27:36,837 - root - INFO - \n",
      "\n",
      "Step: 1, AVG Loss: 2.3706,  AVG Acc: 0.1108, HN Loss: 0.0028754223603755236\n",
      "Step: 6, Node ID: 39, Loss: 2.0563,  Acc: 0.3438:   0%|          | 5/5000 [00:11<2:04:28,  1.50s/it]2024-01-27 02:27:47,171 - root - INFO - \n",
      "\n",
      "Step: 6, AVG Loss: 2.3739,  AVG Acc: 0.1108, HN Loss: 0.003402227535843849\n",
      "Step: 11, Node ID: 3, Loss: 2.5100,  Acc: 0.0156:   0%|          | 10/5000 [00:21<2:10:47,  1.57s/it] 2024-01-27 02:27:57,744 - root - INFO - \n",
      "\n",
      "Step: 11, AVG Loss: 2.3723,  AVG Acc: 0.1103, HN Loss: 0.005932904779911041\n",
      "Step: 16, Node ID: 26, Loss: 2.5723,  Acc: 0.0000:   0%|          | 15/5000 [00:32<2:05:29,  1.51s/it]2024-01-27 02:28:07,994 - root - INFO - \n",
      "\n",
      "Step: 16, AVG Loss: 2.3691,  AVG Acc: 0.1113, HN Loss: 0.005308165680617094\n",
      "Step: 21, Node ID: 0, Loss: 2.2694,  Acc: 0.2188:   0%|          | 20/5000 [00:42<2:04:15,  1.50s/it] 2024-01-27 02:28:18,217 - root - INFO - \n",
      "\n",
      "Step: 21, AVG Loss: 2.3650,  AVG Acc: 0.1121, HN Loss: 0.0033597315195947886\n",
      "Step: 26, Node ID: 44, Loss: 2.1191,  Acc: 0.2031:   0%|          | 25/5000 [00:52<2:03:54,  1.49s/it]2024-01-27 02:28:28,440 - root - INFO - \n",
      "\n",
      "Step: 26, AVG Loss: 2.3684,  AVG Acc: 0.1118, HN Loss: 0.003975704777985811\n",
      "Step: 31, Node ID: 6, Loss: 2.2857,  Acc: 0.2031:   1%|          | 30/5000 [01:03<2:05:35,  1.52s/it] 2024-01-27 02:28:38,765 - root - INFO - \n",
      "\n",
      "Step: 31, AVG Loss: 2.3684,  AVG Acc: 0.1122, HN Loss: 0.003852548310533166\n",
      "Step: 36, Node ID: 33, Loss: 2.3448,  Acc: 0.0625:   1%|          | 35/5000 [01:13<2:05:41,  1.52s/it]2024-01-27 02:28:49,137 - root - INFO - \n",
      "\n",
      "Step: 36, AVG Loss: 2.3650,  AVG Acc: 0.1130, HN Loss: 0.004994998686015606\n",
      "Step: 41, Node ID: 23, Loss: 2.3233,  Acc: 0.0312:   1%|          | 40/5000 [01:23<2:04:48,  1.51s/it]2024-01-27 02:28:59,476 - root - INFO - \n",
      "\n",
      "Step: 41, AVG Loss: 2.3711,  AVG Acc: 0.1121, HN Loss: 0.003735809586942196\n",
      "Step: 46, Node ID: 49, Loss: 2.2147,  Acc: 0.1094:   1%|          | 45/5000 [01:34<2:05:17,  1.52s/it]2024-01-27 02:29:09,794 - root - INFO - \n",
      "\n",
      "Step: 46, AVG Loss: 2.3657,  AVG Acc: 0.1123, HN Loss: 0.0033522876910865307\n",
      "Step: 51, Node ID: 30, Loss: 2.4408,  Acc: 0.0156:   1%|          | 50/5000 [01:44<2:03:31,  1.50s/it]2024-01-27 02:29:20,757 - root - INFO - \n",
      "\n",
      "Step: 51, AVG Loss: 2.3629,  AVG Acc: 0.1119, HN Loss: 0.003029049839824438\n",
      "Step: 56, Node ID: 5, Loss: 2.3072,  Acc: 0.1250:   1%|          | 55/5000 [01:56<2:13:31,  1.62s/it] 2024-01-27 02:29:31,825 - root - INFO - \n",
      "\n",
      "Step: 56, AVG Loss: 2.3711,  AVG Acc: 0.1118, HN Loss: 0.00324754836037755\n",
      "Step: 61, Node ID: 16, Loss: 2.1429,  Acc: 0.1406:   1%|          | 60/5000 [02:08<2:32:26,  1.85s/it]2024-01-27 02:29:45,002 - root - INFO - \n",
      "\n",
      "Step: 61, AVG Loss: 2.3672,  AVG Acc: 0.1128, HN Loss: 0.004146044608205557\n",
      "Step: 66, Node ID: 46, Loss: 2.2803,  Acc: 0.0469:   1%|▏         | 65/5000 [02:22<2:38:56,  1.93s/it]2024-01-27 02:30:02,493 - root - INFO - \n",
      "\n",
      "Step: 66, AVG Loss: 2.3658,  AVG Acc: 0.1132, HN Loss: 0.0057734474539756775\n",
      "Step: 71, Node ID: 49, Loss: 2.2732,  Acc: 0.0938:   1%|▏         | 70/5000 [02:49<4:45:26,  3.47s/it]2024-01-27 02:30:29,454 - root - INFO - \n",
      "\n",
      "Step: 71, AVG Loss: 2.3642,  AVG Acc: 0.1138, HN Loss: 0.0033555012196302414\n",
      "Step: 76, Node ID: 10, Loss: 2.7948,  Acc: 0.0000:   2%|▏         | 75/5000 [03:16<5:17:04,  3.86s/it] 2024-01-27 02:30:56,828 - root - INFO - \n",
      "\n",
      "Step: 76, AVG Loss: 2.3574,  AVG Acc: 0.1133, HN Loss: 0.006859810557216406\n",
      "Step: 81, Node ID: 3, Loss: 2.3875,  Acc: 0.0469:   2%|▏         | 80/5000 [03:43<5:12:26,  3.81s/it]  2024-01-27 02:31:23,170 - root - INFO - \n",
      "\n",
      "Step: 81, AVG Loss: 2.3638,  AVG Acc: 0.1139, HN Loss: 0.005946187302470207\n",
      "Step: 86, Node ID: 23, Loss: 2.3872,  Acc: 0.0781:   2%|▏         | 85/5000 [03:59<3:18:59,  2.43s/it]2024-01-27 02:31:35,100 - root - INFO - \n",
      "\n",
      "Step: 86, AVG Loss: 2.3638,  AVG Acc: 0.1139, HN Loss: 0.0037258698139339685\n",
      "Step: 91, Node ID: 42, Loss: 2.2112,  Acc: 0.2812:   2%|▏         | 90/5000 [04:10<2:23:18,  1.75s/it]2024-01-27 02:31:45,839 - root - INFO - \n",
      "\n",
      "Step: 91, AVG Loss: 2.3602,  AVG Acc: 0.1148, HN Loss: 0.0031497005838900805\n",
      "Step: 96, Node ID: 37, Loss: 2.5817,  Acc: 0.0000:   2%|▏         | 95/5000 [04:20<2:09:04,  1.58s/it]2024-01-27 02:31:56,357 - root - INFO - \n",
      "\n",
      "Step: 96, AVG Loss: 2.3591,  AVG Acc: 0.1152, HN Loss: 0.004891060292720795\n",
      "Step: 101, Node ID: 0, Loss: 2.2568,  Acc: 0.1250:   2%|▏         | 100/5000 [04:31<2:07:19,  1.56s/it] 2024-01-27 02:32:06,942 - root - INFO - \n",
      "\n",
      "Step: 101, AVG Loss: 2.3625,  AVG Acc: 0.1150, HN Loss: 0.0033210741821676493\n",
      "Step: 106, Node ID: 46, Loss: 2.3406,  Acc: 0.0312:   2%|▏         | 105/5000 [04:41<2:04:39,  1.53s/it]2024-01-27 02:32:17,401 - root - INFO - \n",
      "\n",
      "Step: 106, AVG Loss: 2.3542,  AVG Acc: 0.1143, HN Loss: 0.005634878296405077\n",
      "Step: 111, Node ID: 10, Loss: 2.7508,  Acc: 0.0000:   2%|▏         | 110/5000 [04:51<2:02:45,  1.51s/it]2024-01-27 02:32:27,712 - root - INFO - \n",
      "\n",
      "Step: 111, AVG Loss: 2.3635,  AVG Acc: 0.1143, HN Loss: 0.0065956320613622665\n",
      "Step: 116, Node ID: 0, Loss: 2.3195,  Acc: 0.1562:   2%|▏         | 115/5000 [05:02<2:02:17,  1.50s/it] 2024-01-27 02:32:38,086 - root - INFO - \n",
      "\n",
      "Step: 116, AVG Loss: 2.3512,  AVG Acc: 0.1143, HN Loss: 0.0029562152922153473\n",
      "Step: 121, Node ID: 18, Loss: 2.4954,  Acc: 0.0469:   2%|▏         | 120/5000 [05:12<2:06:36,  1.56s/it]2024-01-27 02:32:48,706 - root - INFO - \n",
      "\n",
      "Step: 121, AVG Loss: 2.3654,  AVG Acc: 0.1147, HN Loss: 0.0037622132804244757\n",
      "Step: 126, Node ID: 35, Loss: 2.4585,  Acc: 0.0000:   2%|▎         | 125/5000 [05:23<2:06:12,  1.55s/it]2024-01-27 02:32:59,222 - root - INFO - \n",
      "\n",
      "Step: 126, AVG Loss: 2.3591,  AVG Acc: 0.1126, HN Loss: 0.0034487959928810596\n",
      "Step: 131, Node ID: 33, Loss: 2.2895,  Acc: 0.1094:   3%|▎         | 130/5000 [05:33<2:02:32,  1.51s/it]2024-01-27 02:33:09,440 - root - INFO - \n",
      "\n",
      "Step: 131, AVG Loss: 2.3583,  AVG Acc: 0.1129, HN Loss: 0.004972342401742935\n",
      "Step: 136, Node ID: 26, Loss: 2.6187,  Acc: 0.0000:   3%|▎         | 135/5000 [05:44<2:04:16,  1.53s/it]2024-01-27 02:33:19,866 - root - INFO - \n",
      "\n",
      "Step: 136, AVG Loss: 2.3589,  AVG Acc: 0.1121, HN Loss: 0.005481938365846872\n",
      "Step: 141, Node ID: 14, Loss: 2.3285,  Acc: 0.1562:   3%|▎         | 140/5000 [05:54<2:04:47,  1.54s/it]2024-01-27 02:33:30,333 - root - INFO - \n",
      "\n",
      "Step: 141, AVG Loss: 2.3566,  AVG Acc: 0.1117, HN Loss: 0.003252895548939705\n",
      "Step: 146, Node ID: 45, Loss: 2.4144,  Acc: 0.0469:   3%|▎         | 145/5000 [06:05<2:04:49,  1.54s/it]2024-01-27 02:33:41,952 - root - INFO - \n",
      "\n",
      "Step: 146, AVG Loss: 2.3580,  AVG Acc: 0.1114, HN Loss: 0.0037747016176581383\n",
      "Step: 151, Node ID: 49, Loss: 2.2488,  Acc: 0.1250:   3%|▎         | 150/5000 [06:16<2:11:06,  1.62s/it]2024-01-27 02:33:52,728 - root - INFO - \n",
      "\n",
      "Step: 151, AVG Loss: 2.3602,  AVG Acc: 0.1102, HN Loss: 0.0032659233547747135\n",
      "Step: 156, Node ID: 39, Loss: 2.0722,  Acc: 0.3281:   3%|▎         | 155/5000 [06:27<2:03:17,  1.53s/it]2024-01-27 02:34:02,941 - root - INFO - \n",
      "\n",
      "Step: 156, AVG Loss: 2.3536,  AVG Acc: 0.1103, HN Loss: 0.0032774549908936024\n",
      "Step: 161, Node ID: 22, Loss: 2.3080,  Acc: 0.3438:   3%|▎         | 160/5000 [06:37<2:06:15,  1.57s/it]2024-01-27 02:34:13,604 - root - INFO - \n",
      "\n",
      "Step: 161, AVG Loss: 2.3599,  AVG Acc: 0.1090, HN Loss: 0.003991666715592146\n",
      "Step: 166, Node ID: 30, Loss: 2.4320,  Acc: 0.0000:   3%|▎         | 165/5000 [06:48<2:08:14,  1.59s/it]2024-01-27 02:34:24,678 - root - INFO - \n",
      "\n",
      "Step: 166, AVG Loss: 2.3601,  AVG Acc: 0.1073, HN Loss: 0.004325040616095066\n",
      "Step: 170, Node ID: 7, Loss: 2.5331,  Acc: 0.0000:   3%|▎         | 170/5000 [06:58<3:18:17,  2.46s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_mse(\n\u001b[1;32m      2\u001b[0m     data_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_name,\n\u001b[1;32m      3\u001b[0m     data_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m      4\u001b[0m     classes_per_node\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mclasses_per_node,\n\u001b[1;32m      5\u001b[0m     num_nodes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_nodes,\n\u001b[1;32m      6\u001b[0m     steps\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_steps,\n\u001b[1;32m      7\u001b[0m     inner_steps\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_steps,\n\u001b[1;32m      8\u001b[0m     optim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39moptim,\n\u001b[1;32m      9\u001b[0m     lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlr,\n\u001b[1;32m     10\u001b[0m     inner_lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_lr,\n\u001b[1;32m     11\u001b[0m     embed_lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membed_lr,\n\u001b[1;32m     12\u001b[0m     wd\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mwd,\n\u001b[1;32m     13\u001b[0m     inner_wd\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minner_wd,\n\u001b[1;32m     14\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[1;32m     15\u001b[0m     hyper_hid\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhyper_hid,\n\u001b[1;32m     16\u001b[0m     n_hidden\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mn_hidden,\n\u001b[1;32m     17\u001b[0m     n_kernels\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnkernels,\n\u001b[1;32m     18\u001b[0m     bs\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     19\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     20\u001b[0m     eval_every\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39meval_every,\n\u001b[1;32m     21\u001b[0m     save_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msave_path,\n\u001b[1;32m     22\u001b[0m     seed\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseed\n\u001b[1;32m     23\u001b[0m )\n",
      "Cell \u001b[0;32mIn[29], line 99\u001b[0m, in \u001b[0;36mtrain_mse\u001b[0;34m(data_name, data_path, classes_per_node, num_nodes, steps, inner_steps, optim, lr, inner_lr, embed_lr, wd, inner_wd, embed_dim, hyper_hid, n_hidden, n_kernels, bs, device, eval_every, save_path, seed)\u001b[0m\n\u001b[1;32m     97\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criteria(pred, label)\n\u001b[1;32m     98\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 99\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    101\u001b[0m     inner_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    103\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/lip-reading/lib/python3.11/site-packages/torch/nn/utils/clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[0;32m---> 76\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(grads, clip_coef_clamped\u001b[38;5;241m.\u001b[39mto(device))  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_mse(\n",
    "    data_name=args.data_name,\n",
    "    data_path=args.data_path,\n",
    "    classes_per_node=args.classes_per_node,\n",
    "    num_nodes=args.num_nodes,\n",
    "    steps=args.num_steps,\n",
    "    inner_steps=args.inner_steps,\n",
    "    optim=args.optim,\n",
    "    lr=args.lr,\n",
    "    inner_lr=args.inner_lr,\n",
    "    embed_lr=args.embed_lr,\n",
    "    wd=args.wd,\n",
    "    inner_wd=args.inner_wd,\n",
    "    embed_dim=args.embed_dim,\n",
    "    hyper_hid=args.hyper_hid,\n",
    "    n_hidden=args.n_hidden,\n",
    "    n_kernels=args.nkernels,\n",
    "    bs=args.batch_size,\n",
    "    device=device,\n",
    "    eval_every=args.eval_every,\n",
    "    save_path=args.save_path,\n",
    "    seed=args.seed\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lip-reading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
